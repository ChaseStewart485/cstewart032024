<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day FIVE</title>
    <link rel="stylesheet" href="gobal.css">
<body>
    <header>
        <nav>
            <a href="index.html">Home</a> <a href="one.html">Day 1</a> <a href="two.html">Day 2</a> <a href="three.html">Day 3</a> <a href="four.html">Day 4</a> <a href="five.html">Day 5</a> <a href="six.html">Day 6</a> <a href="seven.html">Day 7</a>
        </nav>
        <h1>Day FIVE - Recovery</h1>
    </header>
    <div>ahh</div>
    <main>
        <h2><a href="https://www.technewsworld.com/story/ai-chatbots-can-be-easy-prey-for-zero-knowledge-hackers-179652.html">AI Chatbots Can Be Easy Prey for ‘Zero-Knowledge’ Hackers</a></h2>
        <h3>John P. Mello Jr.</h3>
        <p>The article talks about how AI is being used to create new cybersecurity threats. A researcher at Cato Networks tricked AI tools like Microsoft Copilot, DeepSeek, and ChatGPT into generating harmful software that could steal login credentials. The researcher used a method called "immersive world," where they created a fake story where making malware was legal, allowing the AI to bypass its safety measures.</p>

        <p>AI systems can sometimes be "jailbroken" by changing how questions are asked, making it possible to trick the system into creating harmful code. While these AI tools have protections, determined attackers can find ways around them.</p>

        <p>Experts suggest testing AI systems with different prompts and using "red teaming" (where experts try to hack into the system) to defend against these attacks. As AI becomes more common, experts are worried about its potential for malicious use, and AI-powered threats are expected to continue to be a major issue in the future.</p>
    </main>
</body>
</html>